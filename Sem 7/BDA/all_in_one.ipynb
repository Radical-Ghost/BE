{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1d860195",
   "metadata": {},
   "source": [
    "# All Experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "712f89f7",
   "metadata": {},
   "source": [
    "### Exp 1: HDFS\n",
    "\n",
    "#### Directory Management\n",
    "\n",
    "| Action | Command |\n",
    "|---:|---|\n",
    "| Create a directory | `hadoop fs -mkdir /mydata` |\n",
    "| Create multiple directories | `hadoop fs -mkdir -p /user/hadoop/input` |\n",
    "| List files in a directory | `hadoop fs -ls /` |\n",
    "| List files recursively | `hadoop fs -ls -R /user/hadoop` |\n",
    "| Remove a directory | `hadoop fs -rm -r /mydata` |\n",
    "\n",
    "#### File Operations\n",
    "\n",
    "| Action | Command |\n",
    "|---:|---|\n",
    "| Copy file from local → HDFS | `hadoop fs -put localfile.txt /mydata/` |\n",
    "| Copy file from HDFS → local | `hadoop fs -get /mydata/output.txt ./` |\n",
    "| Copy file within HDFS | `hadoop fs -cp /mydata/a.txt /backup/a.txt` |\n",
    "| Move file within HDFS | `hadoop fs -mv /mydata/a.txt /backup/a.txt` |\n",
    "| Delete a file | `hadoop fs -rm /mydata/a.txt` |\n",
    "| View file contents | `hadoop fs -cat /mydata/a.txt` |\n",
    "| Display first few lines | `hadoop fs -head /mydata/a.txt` |\n",
    "| Display last few lines | `hadoop fs -tail /mydata/a.txt` |\n",
    "\n",
    "#### System & Information Commands\n",
    "\n",
    "| Action | Command |\n",
    "|---:|---|\n",
    "| Check available HDFS space (human-readable) | `hadoop fs -df -h` |\n",
    "| Check disk usage (human-readable) | `hadoop fs -du -h /mydata` |\n",
    "| Display file checksum | `hadoop fs -checksum /mydata/a.txt` |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10d52a95",
   "metadata": {},
   "source": [
    "### Exp 2 - Word Count using MapReduce concept in Python"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e2e3a30",
   "metadata": {},
   "source": [
    "Hadoop is fast and Hadoop is powerful"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8d45e763",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mapped Output: \n",
      "[('hadoop', 1), ('is', 1), ('fast', 1), ('and', 1), ('hadoop', 1), ('is', 1), ('powerful', 1)]\n",
      "\n",
      "Reduced Output (Word Count): \n",
      "hadoop : 2\n",
      "is : 2\n",
      "fast : 1\n",
      "and : 1\n",
      "powerful : 1\n"
     ]
    }
   ],
   "source": [
    "# ---- Map Phase ----\n",
    "def mapper(sentence):\n",
    "    words = sentence.strip().split()\n",
    "    mapped = []\n",
    "    for word in words:\n",
    "        mapped.append((word.lower(), 1))\n",
    "    return mapped\n",
    "\n",
    "# ---- Reduce Phase ----\n",
    "def reducer(mapped):\n",
    "    reduced = {}\n",
    "    for word, count in mapped:\n",
    "        reduced[word] = reduced.get(word, 0) + count\n",
    "    return reduced\n",
    "\n",
    "# ---- Main Program ----\n",
    "sentence = input(\"Enter a sentence:\")\n",
    "\n",
    "#Map Phase\n",
    "mapped_output = mapper(sentence)\n",
    "print(\"Mapped Output: \")\n",
    "print(mapped_output)\n",
    "\n",
    "#Reduce Phase\n",
    "reduced_output = reducer(mapped_output)\n",
    "print(\"\\nReduced Output (Word Count): \")\n",
    "for word, count in reduced_output.items():\n",
    "    print(f\"{word} : {count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2df47118",
   "metadata": {},
   "source": [
    "### Exp 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42d0a6bc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e6026533",
   "metadata": {},
   "source": [
    "### Exp 5 - FM algo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90fa28a5",
   "metadata": {},
   "source": [
    "a b c a b d e a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "278725a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Estimated number of distinct elements: 6\n"
     ]
    }
   ],
   "source": [
    "from hashlib import sha1\n",
    "\n",
    "def binary_hash(x):\n",
    "    # Convert element to binary hash (first 32 bits for simplicity)\n",
    "    encode = sha1(x.encode()).hexdigest()\n",
    "    binary = bin(int(encode, 16))[2:]\n",
    "    return binary[:32]\n",
    "\n",
    "def fm(stream):\n",
    "    max_zeros = 0\n",
    "    for word in stream:\n",
    "        b = binary_hash(word)\n",
    "        trailing_zeros = len(b) - len(b.rstrip(\"0\"))\n",
    "        max_zeros = max(max_zeros, trailing_zeros)\n",
    "    # φ (correction factor) ≈ 0.77531\n",
    "    return int(2 ** max_zeros * 0.77531)\n",
    "\n",
    "# ---- Main Program ----\n",
    "if __name__ == \"__main__\":\n",
    "    data = input(\"Enter elements separated by spaces: \").split()\n",
    "    result = fm(data)\n",
    "    print(f\"\\nEstimated number of distinct elements: {result}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daec5f7d",
   "metadata": {},
   "source": [
    "### Exp 6 - DIGM\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbcfb8d4",
   "metadata": {},
   "source": [
    "110110101\n",
    "6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "bc83d8c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated count of 1's: 4\n"
     ]
    }
   ],
   "source": [
    "from collections import deque\n",
    "\n",
    "def dgim(stream, window):\n",
    "    buckets = deque()  # each bucket = (timestamp, size)\n",
    "    time = 0\n",
    "\n",
    "    for bit in stream:\n",
    "        time += 1\n",
    "        # Slide the window\n",
    "        while buckets and buckets[0][0] <= time - window:\n",
    "            buckets.popleft()\n",
    "\n",
    "        if bit == '1':\n",
    "            buckets.append((time, 1))\n",
    "            # Merge last two buckets of same size\n",
    "            while len(buckets) >= 3 and buckets[-1][1] == buckets[-2][1]:\n",
    "                last = buckets.pop()\n",
    "                second_last = buckets.pop()\n",
    "                buckets.append((last[0], last[1] * 2))\n",
    "\n",
    "    # Estimate count = sum of bucket sizes (last one counted half)\n",
    "    total = 0\n",
    "    for i, b in enumerate(reversed(buckets)):\n",
    "        if i == 0:\n",
    "            total += b[1] / 2\n",
    "        else:\n",
    "            total += b[1]\n",
    "    return int(total)\n",
    "\n",
    "# ---- Main Program ----\n",
    "if __name__ == \"__main__\":\n",
    "    stream = input(\"Enter binary stream (e.g. 1101011): \")\n",
    "    window = int(input(\"Enter window size: \"))\n",
    "    print(\"Estimated count of 1's:\", dgim(stream, window))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b7748c6",
   "metadata": {},
   "source": [
    "### Exp 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "0e2e124b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "apple → Possibly present\n",
      "banana → Possibly present\n",
      "mango → Definitely not present\n"
     ]
    }
   ],
   "source": [
    "from hashlib import sha256\n",
    "\n",
    "class BloomFilter:\n",
    "    def __init__(self, size=20, hash_count=3):\n",
    "        self.size = size\n",
    "        self.hash_count = hash_count\n",
    "        self.bit_array = [0] * size\n",
    "\n",
    "    def _hashes(self, item):\n",
    "        return [(int(sha256((item+str(i)).encode()).hexdigest(), 16) % self.size)\n",
    "                for i in range(self.hash_count)]\n",
    "\n",
    "    def add(self, item):\n",
    "        for h in self._hashes(item):\n",
    "            self.bit_array[h] = 1\n",
    "\n",
    "    def check(self, item):\n",
    "        return all(self.bit_array[h] for h in self._hashes(item))\n",
    "\n",
    "\n",
    "# --- Main Program ---\n",
    "bf = BloomFilter()\n",
    "\n",
    "# Input items to add\n",
    "items = input(\"Enter elements to add (comma-separated): \").split(\",\")\n",
    "for item in items:\n",
    "    bf.add(item.strip())\n",
    "\n",
    "# Input items to check\n",
    "checks = input(\"Enter elements to check (comma-separated): \").split(\",\")\n",
    "for word in checks:\n",
    "    word = word.strip()\n",
    "    print(f\"{word} → {'Possibly present' if bf.check(word) else 'Definitely not present'}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "neurokit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
